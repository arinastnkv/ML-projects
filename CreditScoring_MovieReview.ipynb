{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit scoring and movie reviews classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arina Sitnikova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll predict whether the customer will repay their credit within 90 days. This is a binary classification problem; we will assign customers into good or bad categories based on our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a function that will replace the NaN values by the median in each column of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_nan_with_median(table):\n",
    "    for col in table.columns:\n",
    "        table[col]= table[col].fillna(table[col].median())\n",
    "    return table   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8158.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3870.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6666.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  age  NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  \\\n",
       "0                 0   64                                     0     0.249908   \n",
       "1                 0   58                                     0  3870.000000   \n",
       "2                 0   41                                     0     0.456127   \n",
       "3                 0   43                                     0     0.000190   \n",
       "4                 1   49                                     0     0.271820   \n",
       "\n",
       "   NumberOfTimes90DaysLate  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                        0                                     0   \n",
       "1                        0                                     0   \n",
       "2                        0                                     0   \n",
       "3                        0                                     0   \n",
       "4                        0                                     0   \n",
       "\n",
       "   MonthlyIncome  NumberOfDependents  \n",
       "0         8158.0                 0.0  \n",
       "1            NaN                 0.0  \n",
       "2         6666.0                 0.0  \n",
       "3        10500.0                 2.0  \n",
       "4          400.0                 0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('credit_scoring_sample.csv', sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribution of the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.777511\n",
       "1    0.222489\n",
       "Name: SeriousDlqin2yrs, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "ax = data['SeriousDlqin2yrs'].hist(orientation='horizontal', color='black')\n",
    "ax.set_xlabel(\"number_of_observations\")\n",
    "ax.set_ylabel(\"unique_value\")\n",
    "ax.set_title(\"Target distribution\")\n",
    "\n",
    "print('Distribution of target:')\n",
    "data['SeriousDlqin2yrs'].value_counts(normalize=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting all the features and dropping the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'NumberOfTime30-59DaysPastDueNotWorse',\n",
       " 'DebtRatio',\n",
       " 'NumberOfTimes90DaysLate',\n",
       " 'NumberOfTime60-89DaysPastDueNotWorse',\n",
       " 'MonthlyIncome',\n",
       " 'NumberOfDependents']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_columns_names = data.columns.values\n",
    "independent_columns_names = [x for x in data if x != 'SeriousDlqin2yrs']\n",
    "independent_columns_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply a function that replaces all NaN values with the median value of the corresponding feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = impute_nan_with_median(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the target and features - now we get a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = table[independent_columns_names]\n",
    "y = table['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll build a Decision Tree Classifier with the help of GridSearchCV, which maximize the area under the ROC curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=17, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look through such values of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_values = [5, 6, 7, 8, 9]\n",
    "max_features_values = [4, 5, 6, 7]\n",
    "tree_params = {'max_depth': max_depth_values,\n",
    "               'max_features': max_features_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid = GridSearchCV(dt, tree_params, cv = skf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=17,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': [5, 6, 7, 8, 9], 'max_features': [4, 5, 6, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8203023476209635, {'max_depth': 7, 'max_features': 6})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.best_score_, tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002758483553592935"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.cv_results_['std_test_score'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we got the best score of 0.82. In addition, the standard deviation of the metric on the cross-validation is just 0.002, which means that the cross-validation is stable under optimal combinations of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try Random Forest Classifier, which is basically an ensemble of decision trees and typically performs much better than a single tree. First, let's build the classifier from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class RandomForestClassifierCustom(BaseEstimator):\n",
    "    def __init__(self, n_estimators=10, max_depth=10, max_features=10, \n",
    "                 random_state=SEED):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.trees = []\n",
    "        self.feat_ids_by_tree = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            np.random.seed(self.random_state + i)\n",
    "            feat_to_use_ids = np.random.choice(range(X.shape[1]), self.max_features, \n",
    "                                               replace=False)\n",
    "            examples_to_use = list(set(np.random.choice(range(X.shape[0]), X.shape[0],\n",
    "                                                        replace=True)))\n",
    "            \n",
    "            self.feat_ids_by_tree.append(feat_to_use_ids)\n",
    "            \n",
    "            dt = DecisionTreeClassifier(max_depth=self.max_depth, \n",
    "                                        max_features=self.max_features, \n",
    "                                        random_state = self.random_state)\n",
    "\n",
    "            dt.fit(X[examples_to_use, :][:, feat_to_use_ids], y[examples_to_use])\n",
    "            self.trees.append(dt)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        pass\n",
    "\n",
    "        predictions = []  \n",
    "        for i in range(self.n_estimators):\n",
    "            feat_to_use_ids = self.feat_ids_by_tree[i]\n",
    "            predictions.append(self.trees[i].predict_proba(X[:,feat_to_use_ids]))\n",
    "        return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832\n"
     ]
    }
   ],
   "source": [
    "cv_auc = cross_val_score(RandomForestClassifierCustom(max_depth=7, max_features=6), \n",
    "                          X.values, y.values, scoring=\"roc_auc\", cv=skf)\n",
    "print(round(np.mean(cv_auc), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we got a higher score. However, when we try the sklearn implementation of the RF, it differs a little bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcf = RandomForestClassifier(class_weight='balanced', n_estimators=10, \n",
    "                             random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree_grid2 = GridSearchCV(rcf, tree_params, cv = skf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 = tree_grid2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8291437173578207"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit2.cv_results_['mean_test_score'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the accuracy is similar to the DT model's. However, here we used DT's hyperparameters that might not be suitable for an ensemble. Let's try other hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_values = range(5, 15)\n",
    "max_features_values = [4, 5, 6, 7]\n",
    "forest_params = {\n",
    "    'max_depth': max_depth_values,\n",
    "    'max_features': max_features_values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(class_weight='balanced', n_estimators=10, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid3 = GridSearchCV(rfc2, forest_params, cv = skf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit3 = tree_grid3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'max_features': 4}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare our results with logistic regression. We will build a pipeline for convenience - first apply scaling, then train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "logit = LogisticRegression(random_state=17, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "logit_pipe = Pipeline([('scaler', scaler), ('logit', logit)])\n",
    "logit_pipe_params = {'logit__C': np.logspace(-8, 8, 17)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_grid4 = GridSearchCV(logit_pipe, logit_pipe_params, cv = skf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit4 = logit_grid4(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878626757307206"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, logistic regression does not perform as well as ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of a small number of features, random forest was proved to be better than logistic regression. However, one of the main disadvantages of trees is how they work with sparse data, for example, with texts. Let's compare logistic regression and random forest in a new task, using the dataset with [movie reviews](https://drive.google.com/file/d/1WDz3EB0MMuQUuUTwZ30c4JJrN8d9shAW/view?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32492\n",
       "0    17508\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"movie_reviews_train.csv\", nrows=50000)\n",
    "\n",
    "X_text = df[\"text\"]\n",
    "y_text = df[\"label\"]\n",
    "\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n",
    "    ('clf', LogisticRegression(solver='liblinear', random_state=17))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Logistic Regression, we'll find the best parameter C using GridSearchCV again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__C': [0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid5 = GridSearchCV(classifier, parameters, cv = skf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit5 = tree_grid5.fit(X_text, y_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8586927181684598"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit5.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score is just under 0.86, which is not bad at all! Now try to perform the same operation with random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=100000, ngram_range=(1, 3))),\n",
    "    ('clf', RandomForestClassifier(n_estimators=10, random_state=SEED, n_jobs=-1))])\n",
    "\n",
    "min_samples_leaf = [1, 2, 3]\n",
    "max_features = [0.3, 0.5, 0.7]\n",
    "max_depth = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest2_params = {\n",
    "    'clf__max_depth': max_depth,\n",
    "    'clf__max_features': max_features,\n",
    "    'clf__min_samples_leaf': min_samples_leaf  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid6 = GridSearchCV(classifier, forest2_params, cv = skf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit6 = tree_grid6.fit(X_text, y_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7472746431514513"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit6.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we assumed, trees did not perform nearly as well. The accuracy is more than 10% lower compared to logistic regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
